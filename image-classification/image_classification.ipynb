{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pylance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgbHnc3Vhh4L",
        "outputId": "537a14d0-ce56-47bd-cc44-455e4d3acb00"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pylance\n",
            "  Downloading pylance-0.19.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: pyarrow>=12 in /usr/local/lib/python3.10/dist-packages (from pylance) (17.0.0)\n",
            "Requirement already satisfied: numpy>=1.22 in /usr/local/lib/python3.10/dist-packages (from pylance) (1.26.4)\n",
            "Downloading pylance-0.19.2-cp39-abi3-manylinux_2_28_x86_64.whl (30.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.5/30.5 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pylance\n",
            "Successfully installed pylance-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LIOXAojgkMB"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M5ejLihJETko"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils import data\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import io\n",
        "import wandb\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd-TbUnzgkMD"
      },
      "source": [
        "### Downloading the Cinic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uuBIMY5pgkME",
        "outputId": "58c6dcf5-2091-4411-8af6-5111f8ce52f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CINIC-10 dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 688M/688M [00:55<00:00, 12.3MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Download time: 55.71 seconds\n",
            "Extracting dataset files...\n",
            "Dataset downloaded and extracted successfully!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import tarfile\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Define the URL for the dataset file\n",
        "data_url = \"https://datashare.ed.ac.uk/bitstream/handle/10283/3192/CINIC-10.tar.gz?sequence=4&isAllowed=y\"\n",
        "\n",
        "# Create the data directory if it doesn't exist\n",
        "data_dir = \"cinic-10-data\"\n",
        "if not os.path.exists(data_dir):\n",
        "    os.makedirs(data_dir)\n",
        "\n",
        "# Download the dataset file\n",
        "print(\"Downloading CINIC-10 dataset...\")\n",
        "data_file = os.path.join(data_dir, \"CINIC-10.tar.gz\")\n",
        "\n",
        "response = requests.get(data_url, stream=True)\n",
        "total_size = int(response.headers.get('content-length', 0))\n",
        "block_size = 1024\n",
        "\n",
        "start_time = time.time()\n",
        "progress_bar = tqdm(total=total_size, unit='iB', unit_scale=True)\n",
        "\n",
        "with open(data_file, 'wb') as f:\n",
        "    for chunk in response.iter_content(chunk_size=block_size):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "            progress_bar.update(len(chunk))\n",
        "\n",
        "end_time = time.time()\n",
        "download_time = end_time - start_time\n",
        "progress_bar.close()\n",
        "\n",
        "print(f\"\\nDownload time: {download_time:.2f} seconds\")\n",
        "\n",
        "# Extract the dataset files\n",
        "print(\"Extracting dataset files...\")\n",
        "with tarfile.open(data_file, 'r:gz') as tar:\n",
        "    tar.extractall(path=data_dir)\n",
        "\n",
        "print(\"Dataset downloaded and extracted successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwMH5rMZgkME"
      },
      "source": [
        "### Converting it to Lance format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPD1kvC_gkMF",
        "outputId": "dd0e8bef-57f7-4c7a-dfbc-f2546b32ce49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing test - airplane: 100%|██████████| 9000/9000 [00:02<00:00, 3708.04it/s]\n",
            "Processing test - truck: 100%|██████████| 9000/9000 [00:02<00:00, 3596.73it/s]\n",
            "Processing test - automobile: 100%|██████████| 9000/9000 [00:02<00:00, 3270.82it/s]\n",
            "Processing test - bird: 100%|██████████| 9000/9000 [00:02<00:00, 4384.90it/s]\n",
            "Processing test - cat: 100%|██████████| 9000/9000 [00:01<00:00, 4557.61it/s]\n",
            "Processing test - dog: 100%|██████████| 9000/9000 [00:01<00:00, 4681.53it/s]\n",
            "Processing test - deer: 100%|██████████| 9000/9000 [00:02<00:00, 4123.24it/s]\n",
            "Processing test - horse: 100%|██████████| 9000/9000 [00:02<00:00, 4450.93it/s]\n",
            "Processing test - frog: 100%|██████████| 9000/9000 [00:01<00:00, 4681.03it/s]\n",
            "Processing test - ship: 100%|██████████| 9000/9000 [00:01<00:00, 4624.47it/s]\n",
            "Processing train - airplane: 100%|██████████| 9000/9000 [00:01<00:00, 4800.86it/s]\n",
            "Processing train - truck: 100%|██████████| 9000/9000 [00:01<00:00, 5000.23it/s]\n",
            "Processing train - automobile: 100%|██████████| 9000/9000 [00:01<00:00, 4990.22it/s]\n",
            "Processing train - bird: 100%|██████████| 9000/9000 [00:01<00:00, 4899.06it/s]\n",
            "Processing train - cat: 100%|██████████| 9000/9000 [00:01<00:00, 4896.61it/s]\n",
            "Processing train - dog: 100%|██████████| 9000/9000 [00:01<00:00, 4942.54it/s]\n",
            "Processing train - deer: 100%|██████████| 9000/9000 [00:02<00:00, 3983.76it/s]\n",
            "Processing train - horse: 100%|██████████| 9000/9000 [00:02<00:00, 4215.44it/s]\n",
            "Processing train - frog: 100%|██████████| 9000/9000 [00:01<00:00, 4768.51it/s]\n",
            "Processing train - ship: 100%|██████████| 9000/9000 [00:01<00:00, 4568.29it/s]\n",
            "Processing valid - airplane: 100%|██████████| 9000/9000 [00:01<00:00, 4992.55it/s]\n",
            "Processing valid - truck: 100%|██████████| 9000/9000 [00:01<00:00, 4724.78it/s]\n",
            "Processing valid - automobile: 100%|██████████| 9000/9000 [00:01<00:00, 4725.30it/s]\n",
            "Processing valid - bird: 100%|██████████| 9000/9000 [00:01<00:00, 4831.66it/s]\n",
            "Processing valid - cat: 100%|██████████| 9000/9000 [00:01<00:00, 4591.97it/s]\n",
            "Processing valid - dog: 100%|██████████| 9000/9000 [00:01<00:00, 4817.18it/s]\n",
            "Processing valid - deer: 100%|██████████| 9000/9000 [00:02<00:00, 3852.40it/s]\n",
            "Processing valid - horse: 100%|██████████| 9000/9000 [00:02<00:00, 4155.46it/s]\n",
            "Processing valid - frog: 100%|██████████| 9000/9000 [00:01<00:00, 4801.47it/s]\n",
            "Processing valid - ship: 100%|██████████| 9000/9000 [00:01<00:00, 4524.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time(sec): 61.66\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pyarrow as pa\n",
        "import lance\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_images(images_folder, split, schema):\n",
        "\n",
        "    # Iterate over the categories within each data type\n",
        "    label_folder = os.path.join(images_folder, split)\n",
        "    for label in os.listdir(label_folder):\n",
        "        label_folder = os.path.join(images_folder, split, label)\n",
        "\n",
        "        # Iterate over the images within each label\n",
        "        for filename in tqdm(os.listdir(label_folder), desc=f\"Processing {split} - {label}\"):\n",
        "            # Construct the full path to the image\n",
        "            image_path = os.path.join(label_folder, filename)\n",
        "\n",
        "            # Read and convert the image to a binary format\n",
        "            with open(image_path, 'rb') as f:\n",
        "                binary_data = f.read()\n",
        "\n",
        "            image_array = pa.array([binary_data], type=pa.binary())\n",
        "            filename_array = pa.array([filename], type=pa.string())\n",
        "            label_array = pa.array([label], type=pa.string())\n",
        "            split_array = pa.array([split], type=pa.string())\n",
        "\n",
        "            # Yield RecordBatch for each image\n",
        "            yield pa.RecordBatch.from_arrays(\n",
        "                [image_array, filename_array, label_array, split_array],\n",
        "                schema=schema\n",
        "            )\n",
        "\n",
        "# Function to write PyArrow Table to Lance dataset\n",
        "def write_to_lance(images_folder, dataset_name, schema):\n",
        "    for split in ['test', 'train', 'valid']:\n",
        "        lance_file_path = os.path.join(images_folder, f\"{dataset_name}_{split}.lance\")\n",
        "\n",
        "        reader = pa.RecordBatchReader.from_batches(schema, process_images(images_folder, split, schema))\n",
        "        lance.write_dataset(\n",
        "            reader,\n",
        "            lance_file_path,\n",
        "            schema,\n",
        "        )\n",
        "\n",
        "\n",
        "dataset_path = \"cinic-10-data\"\n",
        "dataset_name = os.path.basename(dataset_path)\n",
        "\n",
        "start = time.time()\n",
        "schema = pa.schema([\n",
        "    pa.field(\"image\", pa.binary()),\n",
        "    pa.field(\"filename\", pa.string()),\n",
        "    pa.field(\"label\", pa.string()),\n",
        "    pa.field(\"split\", pa.string())\n",
        "])\n",
        "\n",
        "start = time.time()\n",
        "write_to_lance(dataset_path, dataset_name, schema)\n",
        "end = time.time()\n",
        "print(f\"Time(sec): {end - start:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6wbBmvSgkMF"
      },
      "source": [
        "### Defining the Image Classes, Transformation function and other utilities\n",
        "\n",
        "We are defining the different image classes that comes with the `cinic-10` and the transformation functions that needs to be applied to the images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "toSrp4xvFlwu"
      },
      "outputs": [],
      "source": [
        "# Define the image classes\n",
        "classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# transformation function\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NwTeSSQFyHz",
        "outputId": "c3393361-d806-4e90-d066-f7c1b9e2b830"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(\"CUDA is available\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CUDA is not available, using CPU instead\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzGW665qgkMG"
      },
      "source": [
        "# Custom Image Dataset Class\n",
        "\n",
        "We are going to use a custom Dataset class to load the images from the `cinic-10` Image Lance dataset. To know more about how we created a Lance image dataset, refer to `convert-any-image-dataset-to-lance.py` script in `converters` folder.\n",
        "\n",
        "\n",
        "Along with it, we are passing the adequate number of different classes and transformation function that needs to be applied to the images.\n",
        "\n",
        "To make sure the cnn architecture remains constant for all kind of images, we are going to apply the `RGB transformation` to the various images to maintain the same color space with a default setting of 3 channels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_SPgIzHxgkMH"
      },
      "outputs": [],
      "source": [
        "# Define the custom dataset class\n",
        "class CustomImageDataset(data.Dataset):\n",
        "    def __init__(self, classes, lance_dataset, transform=None):\n",
        "        self.classes = classes\n",
        "        self.ds = lance.dataset(lance_dataset)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.ds.count_rows()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        raw_data = self.ds.take([idx], columns=['image', 'label']).to_pydict()\n",
        "        img_data, label = raw_data['image'][0], raw_data['label'][0]\n",
        "\n",
        "        img = Image.open(io.BytesIO(img_data))\n",
        "\n",
        "        # Convert grayscale images to RGB\n",
        "        if img.mode != 'RGB':\n",
        "            img = img.convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = self.classes.index(label)\n",
        "        return img, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTNyCMCOgkMH"
      },
      "source": [
        "# Model hyperparameters and Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j2ZjNsWFF_jq"
      },
      "outputs": [],
      "source": [
        "lr = 1e-3\n",
        "momentum = 0.9\n",
        "number_of_epochs = 10\n",
        "cinic_root = \"cinic-10-data\"\n",
        "train_dataset_path = \"cinic-10-data/cinic-10-data_train.lance/\"\n",
        "test_dataset_path = \"cinic-10-data/cinic-10-data_test.lance/\"\n",
        "validation_dataset_path = \"cinic-10-data/cinic-10-data_valid.lance/\"\n",
        "model_batch_size = 64\n",
        "batches_to_train = 256\n",
        "batches_to_val = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9smvynygkMI"
      },
      "source": [
        "### Using a pre-trained `ResNet-34` architecture\n",
        "\n",
        "We are going to use a pre-trained `ResNet-34` architecture to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "edo9eWTXgkMJ"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Net, self).__init__()\n",
        "        self.resnet = models.resnet34(pretrained=True)\n",
        "        num_ftrs = self.resnet.fc.in_features\n",
        "        self.resnet.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.resnet(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwRhcVFegkMJ"
      },
      "source": [
        "# Training Function\n",
        "\n",
        "`train_model` is the standard training function that we are going to use to train our CNN model. We will pass the relevant dataloaders, model, loss function, optimizer, device , batches to train and number of epochs to train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1uwpoeriGPlk"
      },
      "outputs": [],
      "source": [
        "def train_model(train_loader, val_loader, model, criterion, optimizer, device, num_epochs, batch_to_train, batch_to_val, run_name):\n",
        "    wandb.init(project=\"cinic-10\", name = run_name)\n",
        "\n",
        "    model.train()\n",
        "    total_start = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        total_batch_start = time.time()\n",
        "\n",
        "        with tqdm(enumerate(train_loader), total=batch_to_train, desc=f\"Epoch {epoch+1}\") as pbar_epoch:\n",
        "            for i, data in pbar_epoch:\n",
        "                if i >= batch_to_train:\n",
        "                    break\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                if i % 10 == 0:\n",
        "                    pbar_epoch.set_postfix({'Loss': loss.item()})\n",
        "                    pbar_epoch.update(10)\n",
        "\n",
        "        per_epoch_time = time.time() - total_batch_start\n",
        "        avg_loss = running_loss / batch_to_train\n",
        "        print(f'Epoch {epoch+1}/{num_epochs} | Avg Loss: {avg_loss:.4f} | Time: {per_epoch_time:.4f} sec')\n",
        "        wandb.log({\"Loss\": loss.item()})\n",
        "        wandb.log({\"Epoch Duration\": per_epoch_time})\n",
        "\n",
        "    total_training_time = (time.time() - total_start) / 60\n",
        "    print(f\"Total Training Time: {total_training_time:.4f} mins\")\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    correct_val = 0\n",
        "    total_val = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            if i >= batch_to_val:\n",
        "                break\n",
        "            images_val, labels_val = data[0].to(device), data[1].to(device)\n",
        "            outputs_val = model(images_val)\n",
        "            _, predicted_val = torch.max(outputs_val.data, 1)\n",
        "            total_val += labels_val.size(0)\n",
        "            correct_val += (predicted_val == labels_val).sum().item()\n",
        "\n",
        "    val_accuracy = 100 * correct_val / total_val\n",
        "    print(f'Validation Accuracy: {val_accuracy:.2f}%')\n",
        "    wandb.log({\"Validation Accuracy\": val_accuracy})\n",
        "    print('Finished Training')\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "302JONSKGXY8"
      },
      "outputs": [],
      "source": [
        "lance_train_dataset = CustomImageDataset(classes, train_dataset_path, transform=transform_train)\n",
        "lance_test_dataset = CustomImageDataset(classes, test_dataset_path, transform=transform_test)\n",
        "lance_val_dataset = CustomImageDataset(classes, validation_dataset_path, transform=transform_val)\n",
        "\n",
        "lance_train_loader = torch.utils.data.DataLoader(lance_train_dataset, batch_size=model_batch_size, shuffle=True)\n",
        "lance_test_loader = torch.utils.data.DataLoader(lance_test_dataset, batch_size=model_batch_size, shuffle=True)\n",
        "lance_val_loader = torch.utils.data.DataLoader(lance_val_dataset, batch_size=model_batch_size, shuffle=True)\n",
        "\n",
        "vanilla_train_dataset = ImageFolder(root=f'{cinic_root}/train', transform=transform_train)\n",
        "vanilla_test_dataset = ImageFolder(root=f'{cinic_root}/test', transform=transform_test)\n",
        "vanilla_val_dataset = ImageFolder(root=f'{cinic_root}/valid', transform=transform_val)\n",
        "\n",
        "vanilla_train_loader = torch.utils.data.DataLoader(vanilla_train_dataset, batch_size=model_batch_size, shuffle=True)\n",
        "vanilla_test_loader = torch.utils.data.DataLoader(vanilla_test_dataset, batch_size=model_batch_size, shuffle=True)\n",
        "vanilla_val_loader = torch.utils.data.DataLoader(vanilla_val_dataset, batch_size=model_batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FKM43muUgkMJ",
        "outputId": "2019dc91-e767-453b-e357-13cd53519785"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:q1hy6thp) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch Duration</td><td>▁</td></tr><tr><td>Loss</td><td>▁</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch Duration</td><td>18.55445</td></tr><tr><td>Loss</td><td>0.99658</td></tr><tr><td>Validation Accuracy</td><td>57.4585</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">vanilla_run</strong> at: <a href='https://wandb.ai/nlp-vn/cinic-10/runs/q1hy6thp' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10/runs/q1hy6thp</a><br/> View project at: <a href='https://wandb.ai/nlp-vn/cinic-10' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241128_205036-q1hy6thp/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:q1hy6thp). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241128_205637-nsu68iyk</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nlp-vn/cinic-10/runs/nsu68iyk' target=\"_blank\">lance_run</a></strong> to <a href='https://wandb.ai/nlp-vn/cinic-10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nlp-vn/cinic-10' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nlp-vn/cinic-10/runs/nsu68iyk' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10/runs/nsu68iyk</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 256/256 [00:35<00:00,  7.20it/s, Loss=1.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Avg Loss: 1.6171 | Time: 35.5425 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 256/256 [00:35<00:00,  7.24it/s, Loss=1.22]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 | Avg Loss: 1.2660 | Time: 35.3810 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 256/256 [00:35<00:00,  7.15it/s, Loss=1.29]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 | Avg Loss: 1.1633 | Time: 35.8063 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 256/256 [00:34<00:00,  7.42it/s, Loss=0.959]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 | Avg Loss: 1.0793 | Time: 34.5191 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 256/256 [00:35<00:00,  7.20it/s, Loss=0.932]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 | Avg Loss: 1.0390 | Time: 35.5875 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 256/256 [00:35<00:00,  7.24it/s, Loss=0.927]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 | Avg Loss: 0.9902 | Time: 35.3540 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 256/256 [00:35<00:00,  7.28it/s, Loss=1.02]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 | Avg Loss: 0.9633 | Time: 35.1669 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 256/256 [00:36<00:00,  7.10it/s, Loss=0.892]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 | Avg Loss: 0.9271 | Time: 36.0747 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 256/256 [00:34<00:00,  7.34it/s, Loss=1.03]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 | Avg Loss: 0.9135 | Time: 34.8945 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 256/256 [00:35<00:00,  7.21it/s, Loss=0.709]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 | Avg Loss: 0.8700 | Time: 35.5085 sec\n",
            "Total Training Time: 5.8976 mins\n",
            "Validation Accuracy: 67.14%\n",
            "Finished Training\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:nsu68iyk) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch Duration</td><td>▆▅▇▁▆▅▄█▃▅</td></tr><tr><td>Loss</td><td>▆▄▃▃█▂▁▄▂▂</td></tr><tr><td>Validation Accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch Duration</td><td>35.50854</td></tr><tr><td>Loss</td><td>0.83529</td></tr><tr><td>Validation Accuracy</td><td>67.13867</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">lance_run</strong> at: <a href='https://wandb.ai/nlp-vn/cinic-10/runs/nsu68iyk' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10/runs/nsu68iyk</a><br/> View project at: <a href='https://wandb.ai/nlp-vn/cinic-10' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241128_205637-nsu68iyk/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:nsu68iyk). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241128_210247-v4t53ioh</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nlp-vn/cinic-10/runs/v4t53ioh' target=\"_blank\">vanilla_run</a></strong> to <a href='https://wandb.ai/nlp-vn/cinic-10' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nlp-vn/cinic-10' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nlp-vn/cinic-10/runs/v4t53ioh' target=\"_blank\">https://wandb.ai/nlp-vn/cinic-10/runs/v4t53ioh</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████| 256/256 [00:19<00:00, 13.14it/s, Loss=0.775]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Avg Loss: 0.8544 | Time: 19.4920 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 256/256 [00:19<00:00, 12.84it/s, Loss=0.754]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/10 | Avg Loss: 0.8458 | Time: 19.9490 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 256/256 [00:16<00:00, 15.60it/s, Loss=0.946]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/10 | Avg Loss: 0.8293 | Time: 16.4239 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 256/256 [00:16<00:00, 15.93it/s, Loss=0.634]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10 | Avg Loss: 0.8216 | Time: 16.0803 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 256/256 [00:16<00:00, 15.58it/s, Loss=0.673]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/10 | Avg Loss: 0.7931 | Time: 16.4397 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 256/256 [00:16<00:00, 15.49it/s, Loss=0.563]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/10 | Avg Loss: 0.7901 | Time: 16.5322 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 256/256 [00:17<00:00, 14.85it/s, Loss=0.794]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/10 | Avg Loss: 0.7575 | Time: 17.2514 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 256/256 [00:16<00:00, 15.86it/s, Loss=0.789]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/10 | Avg Loss: 0.7552 | Time: 16.1512 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 256/256 [00:16<00:00, 15.80it/s, Loss=0.785]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/10 | Avg Loss: 0.7363 | Time: 16.2153 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 256/256 [00:16<00:00, 15.48it/s, Loss=0.823]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/10 | Avg Loss: 0.7201 | Time: 16.5495 sec\n",
            "Total Training Time: 2.8517 mins\n",
            "Validation Accuracy: 70.29%\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "net = Net(len(classes)).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "lance_trained_model = train_model(lance_train_loader, lance_val_loader, net, criterion, optimizer, device, number_of_epochs, batches_to_train, batches_to_val, run_name = \"lance_run\")\n",
        "vanilla_trained_model = train_model(vanilla_train_loader, vanilla_val_loader, net, criterion, optimizer, device, number_of_epochs, batches_to_train, batches_to_val, run_name = \"vanilla_run\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mSfoUrdDP1hw"
      },
      "outputs": [],
      "source": [
        "DIR_PATH = '../community-examples'\n",
        "\n",
        "# Define the file paths\n",
        "PATH_LANCE_MODEL = os.path.join(DIR_PATH, 'cinic_resnet_lance_model.pth')\n",
        "PATH_VANILLA_MODEL = os.path.join(DIR_PATH, 'cinic_resnet_vanilla_model.pth')\n",
        "\n",
        "# Check if the directory exists or not, if not create it\n",
        "if not os.path.isdir(DIR_PATH):\n",
        "    os.mkdir(DIR_PATH)\n",
        "\n",
        "# Save the models\n",
        "torch.save(vanilla_trained_model.state_dict(), PATH_VANILLA_MODEL)\n",
        "torch.save(lance_trained_model.state_dict(), PATH_LANCE_MODEL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6jnPntXP5Yr",
        "outputId": "ca7b3929-4286-48b7-961e-d2e04afc6cdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing lance: 100%|██████████| 1407/1407 [02:22<00:00,  9.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 69.71% for lance dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing vanilla: 100%|██████████| 1407/1407 [01:15<00:00, 18.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 69.71% for vanilla dataloader\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "def test_model(test_loader, model, device, type):\n",
        "    model.eval()\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(test_loader, desc=f\"Testing {type}\"):\n",
        "            images_test, labels_test = data[0].to(device), data[1].to(device)\n",
        "            outputs_test = model(images_test)\n",
        "            _, predicted_test = torch.max(outputs_test.data, 1)\n",
        "            total_test += labels_test.size(0)\n",
        "            correct_test += (predicted_test == labels_test).sum().item()\n",
        "\n",
        "    test_accuracy = 100 * correct_test / total_test\n",
        "    print(f'Test Accuracy: {test_accuracy:.2f}% for {type} dataloader')\n",
        "\n",
        "# Assuming 'device' is defined, e.g., device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "test_model(lance_test_loader, lance_trained_model, device, \"lance\")\n",
        "test_model(vanilla_test_loader, vanilla_trained_model, device, \"vanilla\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}