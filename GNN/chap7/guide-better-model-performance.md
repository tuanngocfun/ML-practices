# **Graph Attention Networks (GATv2) - PyTorch Geometric**

## ğŸ“Œ **Má»¥c tiÃªu**
- **Táº£i vÃ  xá»­ lÃ½ dataset Cora** tá»« PyTorch Geometric.
- **XÃ¢y dá»±ng mÃ´ hÃ¬nh GATv2 vá»›i cÃ¡c cáº£i tiáº¿n**.
- **Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ hiá»‡u suáº¥t**.
- **PhÃ¢n tÃ­ch Ä‘á»™ chÃ­nh xÃ¡c theo node degree**.

---

## ğŸ“¥ **1. CÃ i Ä‘áº·t thÆ° viá»‡n**
```python
# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t (chá»‰ cháº¡y náº¿u chÆ°a cÃ i Ä‘áº·t)
!pip install torch torch-geometric scikit-learn
```

---

## ğŸ“Œ **2. Táº£i Dataset Cora**
```python
import torch
from torch_geometric.datasets import Planetoid
from torch_geometric.utils import add_self_loops
from sklearn.preprocessing import StandardScaler

# Load dataset (Cora)
dataset = Planetoid(root=".", name="Cora")
data = dataset[0]

# Chuáº©n hÃ³a Ä‘áº·c trÆ°ng Ä‘áº§u vÃ o
scaler = StandardScaler()
data.x = torch.tensor(scaler.fit_transform(data.x.numpy()), dtype=torch.float)

# ThÃªm self-loops vÃ o Ä‘á»“ thá»‹
data.edge_index, _ = add_self_loops(data.edge_index)

print(f"Dataset: {dataset.name}")
print(f"Sá»‘ node: {data.x.shape[0]}, Sá»‘ features: {data.x.shape[1]}")
print(f"Sá»‘ cáº¡nh: {data.edge_index.shape[1]}")
```

---

## ğŸ— **3. XÃ¢y dá»±ng mÃ´ hÃ¬nh GATv2**
```python
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch_geometric.nn import GATv2Conv

class GATv2Model(nn.Module):
    def __init__(self, dim_in, dim_h, dim_out, heads=8):
        super().__init__()
        self.gat1 = GATv2Conv(dim_in, dim_h, heads=heads)
        self.gat2 = GATv2Conv(dim_h * heads, dim_h, heads=heads)
        self.gat3 = GATv2Conv(dim_h * heads, dim_out, heads=1)

    def forward(self, x, edge_index):
        h = F.dropout(x, p=0.6, training=self.training)
        h = self.gat1(h, edge_index)
        h = F.elu(h)
        h = F.dropout(h, p=0.6, training=self.training)
        h = self.gat2(h, edge_index)
        h = F.elu(h)
        h = F.dropout(h, p=0.6, training=self.training)
        h = self.gat3(h, edge_index)
        return F.log_softmax(h, dim=1)
```

---

## ğŸ“Œ **4. HÃ m Huáº¥n luyá»‡n vá»›i Early Stopping**
```python
    def fit(self, data, epochs=100, lr=0.005, weight_decay=0.0005):
        criterion = nn.CrossEntropyLoss()
        optimizer = optim.Adam(self.parameters(), lr=lr, weight_decay=weight_decay)
        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)

        best_val_loss = float('inf')
        early_stop_patience = 10
        no_improve_count = 0

        self.train()
        for epoch in range(epochs):
            optimizer.zero_grad()
            out = self(data.x, data.edge_index)
            loss = criterion(out[data.train_mask], data.y[data.train_mask])
            loss.backward()
            optimizer.step()

            val_loss = criterion(out[data.val_mask], data.y[data.val_mask])
            scheduler.step(val_loss)

            print(f"Epoch {epoch+1}: Train Loss = {loss:.4f}, Val Loss = {val_loss:.4f}")

            # Early stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                no_improve_count = 0
            else:
                no_improve_count += 1
                if no_improve_count >= early_stop_patience:
                    print(f"Early stopping at epoch {epoch+1}")
                    break
```

---

## ğŸ§ª **5. ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh**
```python
@torch.no_grad()
def test(self, data):
    self.eval()
    out = self(data.x, data.edge_index)
    acc = (out.argmax(dim=1)[data.test_mask] == data.y[data.test_mask]).sum().item() / data.test_mask.sum().item()
    return acc

# ThÃªm phÆ°Æ¡ng thá»©c test vÃ o class
GATv2Model.test = test
```

---

## ğŸš€ **6. Khá»Ÿi táº¡o mÃ´ hÃ¬nh & Huáº¥n luyá»‡n**
```python
dim_in = dataset.num_features
dim_h = 32
dim_out = dataset.num_classes

gat = GATv2Model(dim_in, dim_h, dim_out)

print("Training GATv2...")
gat.fit(data, epochs=100)

# Kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p test
test_acc = gat.test(data)
print(f"GATv2 Test Accuracy: {test_acc * 100:.2f}%")
```

---

## ğŸ“Š **7. PhÃ¢n tÃ­ch Ä‘á»™ chÃ­nh xÃ¡c theo Node Degree**
```python
import matplotlib.pyplot as plt
import numpy as np
from torch_geometric.utils import degree

# Láº¥y Ä‘áº§u ra cá»§a mÃ´ hÃ¬nh
out = gat(data.x, data.edge_index)
degrees = degree(data.edge_index[0]).numpy()

accuracies = []
sizes = []

for i in range(0, 6):
    mask = np.where(degrees == i)[0]
    if len(mask) > 0:
        acc = (out.argmax(dim=1)[mask] == data.y[mask]).sum().item() / len(mask)
        accuracies.append(acc)
        sizes.append(len(mask))
    else:
        accuracies.append(0)
        sizes.append(0)

mask = np.where(degrees > 5)[0]
if len(mask) > 0:
    acc = (out.argmax(dim=1)[mask] == data.y[mask]).sum().item() / len(mask)
    accuracies.append(acc)
    sizes.append(len(mask))

# Váº½ biá»ƒu Ä‘á»“
fig, ax = plt.subplots()
ax.set_xlabel('Node degree')
ax.set_ylabel('Accuracy score')
plt.bar(['0', '1', '2', '3', '4', '5', '6+'], accuracies)

for i in range(len(accuracies)):
    plt.text(i, accuracies[i], f'{accuracies[i] * 100:.2f}%', ha='center', color='black')
    plt.text(i, accuracies[i] / 2, sizes[i], ha='center', color='white')

plt.show()
```

---

## **ğŸ¯ Káº¿t quáº£ mong Ä‘á»£i**
- **Test Accuracy ~80% trÃªn dataset Cora**.
- **Biá»ƒu Ä‘á»“ Accuracy theo Node Degree** hiá»ƒn thá»‹ rÃµ áº£nh hÆ°á»Ÿng cá»§a connectivity.

ğŸ“Œ **BÃ¢y giá» báº¡n cÃ³ thá»ƒ cháº¡y toÃ n bá»™ notebook vÃ  kiá»ƒm tra káº¿t quáº£! ğŸš€**
