{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<p>\n",
    "  <b>AI Lab: Deep Learning for Computer Vision</b><br>\n",
    "  <b><a href=\"https://www.wqu.edu/\">WorldQuant University</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  <p>\n",
    "    <center><b>Usage Guidelines</b></center>\n",
    "  </p>\n",
    "  <p>\n",
    "    This file is licensed under <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International</a>.\n",
    "  </p>\n",
    "  <p>\n",
    "    You <b>can</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Download this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Post this file in public repositories</li>\n",
    "    </ul>\n",
    "    You <b>must always</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: green\">✓</span> Give credit to <a href=\"https://www.wqu.edu/\">WorldQuant University</a> for the creation of this file</li>\n",
    "      <li><span style=\"color: green\">✓</span> Provide a <a href=\"https://creativecommons.org/licenses/by-nc-nd/4.0/\">link to the license</a></li>\n",
    "    </ul>\n",
    "    You <b>cannot</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: red\">✗</span> Create derivatives or adaptations of this file</li>\n",
    "      <li><span style=\"color: red\">✗</span> Use this file for commercial purposes</li>\n",
    "    </ul>\n",
    "  </p>\n",
    "  <p>\n",
    "    Failure to follow these guidelines is a violation of your terms of service and could lead to your expulsion from WorldQuant University and the revocation your certificate.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "###  Error Caused By Incorrect Input Layer Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's start with imports, then define and run a PyTorch model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "linear1 = nn.Linear(in_features=3200, out_features=128)\n",
    "model.append(linear1)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "linear2 = nn.Linear(in_features=128, out_features=64)\n",
    "model.append(linear2)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "linear3 = nn.Linear(in_features=64, out_features=10)\n",
    "model.append(linear3)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(32, 100))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The code execution fails, resulting in a `RuntimeError`. When interpreting a Python stack trace, always begin at the **bottom** and work your way **up**. PyTorch errors are typically more verbose than standard Python errors. In this instance, we're encountering a `RuntimeError`, signaling an issue during model execution. Scanning **upwards**, we find the line `output = model(input_tensor)` near the top. The lower lines in the stack trace show different function calls from the PyTorch library, but they're not the most important part of the error message. The key is to focus on the code that was written in the notebook.\n",
    "\n",
    "The line `output = model(input_tensor)` triggers the error as it feeds the input data to the model for the forward pass. During the forward pass, the model sequentially applies layers and operations to compute output predictions. The failure occurs due to misaligned layer dimensions. The error message provides critical information: `mat1 and mat2 shapes cannot be multiplied (32x100 and 3200x128)`.\n",
    "\n",
    "At the heart of deep learning is matrix algebra. Matrix algebra has very specific rules for matrix multiplication. One crucial rule is that the number of columns in the first matrix (mat1) must equal the number of rows in the second matrix (mat2). This condition is not met in the current input, where the first matrix has 100 columns and the second matrix has 3200 rows.\n",
    "\n",
    "This error commonly stems from incorrectly specifying layer dimensions, particularly in the input layer. The value passed to the `in_features` argument must exactly match the input data dimensions. Dimensional mismatches often lead to runtime errors or unexpected model behavior.\n",
    "\n",
    "To resolve this issue, let's carefully review the code to identify the dimensional inconsistency. Printing the shape of the model and data can help debugging. This error can be fixed by adjusting the first layer to `in_features=100`, thus matching the size of the input tensor. Let's define another version of the model with that change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a revised model\n",
    "model = torch.nn.Sequential()\n",
    "linear1 = nn.Linear(\n",
    "    in_features=100, out_features=128\n",
    ")  # This line was changed to match input size\n",
    "model.append(linear1)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "linear2 = nn.Linear(in_features=128, out_features=64)\n",
    "model.append(linear2)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "linear3 = nn.Linear(in_features=64, out_features=10)\n",
    "model.append(linear3)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(32, 100))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The code now runs because the model can make a successful forward pass.\n",
    "\n",
    "Now is your chance to try to solve a similar error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Task 2.1.1:** Modify the model to match the input tensor size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a revised model\n",
    "model = torch.nn.Sequential()\n",
    "linear1 = nn.Linear(in_features=32, out_features=64)\n",
    "model.append(linear1)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "linear2 = nn.Linear(in_features=64, out_features=32)\n",
    "model.append(linear2)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "linear3 = nn.Linear(in_features=32, out_features=1)\n",
    "model.append(linear3)\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(torch.nn.Dropout())\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(32, 10))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Error Caused By Adding The Same Layer Twice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's build another PyTorch model, this time a Convolutional Neural Network (CNN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "model.append(conv1)\n",
    "model.append(torch.nn.ReLU())\n",
    "max_pool1 = nn.MaxPool2d(2, 2)\n",
    "model.append(max_pool1)\n",
    "model.append(conv1)  # Add the same layer again\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(max_pool1)\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "When the cell is executed, it also generates a `RuntimeError`. The message \"Given groups=1, weight of size [16, 3, 3, 3], expected input[1, 16, 224, 224] to have 3 channels, but got 16 channels instead\" is a clue that the dimensions do not line up correctly. That is caused because the same layer was accidentally added twice to a model. This is typically caused by a copy-and-paste mistake.\n",
    "\n",
    "To resolve this issue, you'll need to carefully review your code and identify where this dimensional inconsistency occurs. Pay particular attention to the layer where you might have accidentally duplicated a component, leading to unexpected channel dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The code can be fixed by adding a different layer that has the appropriate dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a revised model\n",
    "model = torch.nn.Sequential()\n",
    "conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1)\n",
    "model.append(conv1)\n",
    "model.append(torch.nn.ReLU())\n",
    "max_pool1 = nn.MaxPool2d(2, 2)\n",
    "model.append(max_pool1)\n",
    "# Define and add a new layer instead of the same previous one\n",
    "conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "model.append(conv2)\n",
    "model.append(torch.nn.ReLU())\n",
    "max_pool2 = nn.MaxPool2d(2, 2)\n",
    "model.append(max_pool2)\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now you should try to fix a similar mistake, by using the traceback information to find the mismatched dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Task 2.1.2:** Fix a `RuntimeError` by not adding the same layer twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=2, padding=1)\n",
    "model.append(conv1)\n",
    "model.append(torch.nn.ReLU())\n",
    "max_pool1 = nn.MaxPool2d(2, 2)\n",
    "model.append(max_pool1)\n",
    "conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "model.append(conv2)\n",
    "model.append(torch.nn.ReLU())\n",
    "max_pool2 = nn.MaxPool2d(2, 2)\n",
    "model.append(max_pool2)\n",
    "conv3 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, padding=1)\n",
    "model.append(conv3)\n",
    "model.append(torch.nn.ReLU())\n",
    "max_pool3 = nn.MaxPool2d(2, 2)\n",
    "model.append(max_pool3)\n",
    "conv4 = nn.Conv2d(in_channels=8, out_channels=1, kernel_size=2, padding=1)\n",
    "\n",
    "model.append(conv3)\n",
    "model.append(torch.nn.ReLU())\n",
    "max_pool4 = nn.MaxPool2d(2, 2)\n",
    "model.append(max_pool4)\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 1, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Error Caused By Forgetting to Flatten "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Let's construct another model with multiple convolutional layers (Conv2d) followed by several fully connected layers (Linear). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(nn.MaxPool2d(2, 2))\n",
    "model.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1))\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(nn.MaxPool2d(2, 2))\n",
    "model.append(nn.Linear(in_features=32 * 56 * 56, out_features=128))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.Linear(in_features=128, out_features=10))\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Upon execution, this model generates a `RuntimeError`. Let's analyze this error message as we did in the previous example. Concentrate on the matrix dimension mismatch: \"the mat1 and mat2 shapes cannot be multiplied (7168x224 and 1605632x128)\".\n",
    "\n",
    "The error in the code stems from attempting to feed the output of the max pooling layer (`MaxPool2d`) directly into fully connected layers (`Linear`). This fails because `Conv2d` layers produce a 4D tensor (`batch_size`, `channels`, `height`, `width`), while `Linear` layers expect a 2D tensor (`batch_size`, `features`). \n",
    "\n",
    "To resolve this issue, the tensor needs to be flattened before it enters the fully connected layers. This flattening step transforms the 4D output from the convolutional layers into a 2D tensor that the Linear layers can process. Without this crucial step, the dimensions of the data flowing through your model become incompatible, leading to the observed error.\n",
    "\n",
    "Here is the corrected code that flattens the tensor before passing it to the fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(nn.MaxPool2d(2, 2))\n",
    "model.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1))\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(nn.MaxPool2d(2, 2))\n",
    "model.append(torch.nn.Flatten())  # Flatten the tensor before passing to Linear layers\n",
    "model.append(nn.Linear(in_features=32 * 56 * 56, out_features=128))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.Linear(in_features=128, out_features=10))\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a try yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.1.3:** Fix a `RuntimeError` caused by forgetting to flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "model.append(nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "model.append(nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "model.append(nn.Linear(in_features=64 * 28 * 28, out_features=256))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.Linear(in_features=256, out_features=64))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.Linear(in_features=64, out_features=10))\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Caused By Incorrect Layer Size After Flattening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another example of convolutional layer followed by a linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(nn.MaxPool2d(2, 2))\n",
    "model.append(torch.nn.Flatten())\n",
    "model.append(nn.Linear(in_features=16 * 224 * 224, out_features=32))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.Linear(in_features=32, out_features=10))\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "This model generates a `RuntimeError` when attempting to execute the cell due to a matrix dimension mismatch: \"mat1 and mat2 shapes cannot be multiplied (1x200704 and 802816x32).\" \n",
    "\n",
    "The issue arises from incorrectly specifying the size of the linear layer after flattening from a convolutional layer. The code specifies`model.append(nn.Linear(in_features=16 * 224 * 224, out_features=32))`, but the `in_features` value is incorrect. While 16 is the correct number based on the output channels from the `Conv2d` layer, the spatial dimensions should be 112x112 (half of 224x224 due to the `MaxPool2d(2, 2)` layer). The correct value for `in_features` should be 16 * 112 * 112.\n",
    "\n",
    "Let's update the model with this change and try running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "model.append(nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1))\n",
    "model.append(torch.nn.ReLU())\n",
    "model.append(nn.MaxPool2d(2, 2))\n",
    "model.append(torch.nn.Flatten())\n",
    "model.append(\n",
    "    nn.Linear(in_features=16 * 112 * 112, out_features=32)\n",
    ")  # in_features modified to match the expected number of dimensions\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.Linear(in_features=32, out_features=10))\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After making the change to the input dimensions of the linear layer, the model can be successfully executed.\n",
    "\n",
    "Your turn to debug a similar issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 2.1.4:** Fix a `RuntimeError` caused by incorrect dimensions after flattening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model\n",
    "model = torch.nn.Sequential()\n",
    "model.append(\n",
    "    nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3)\n",
    ")\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n",
    "model.append(nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "model.append(nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1))\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "model.append(nn.Flatten())\n",
    "\n",
    "model.append(nn.Linear(in_features=128 * 7 * 7, out_features=1000))\n",
    "\n",
    "model.append(nn.ReLU())\n",
    "model.append(nn.Linear(in_features=1000, out_features=10))\n",
    "print(model)\n",
    "\n",
    "# Create a random input tensor\n",
    "input_tensor = torch.randn(size=(1, 3, 224, 224))\n",
    "print(\"Input shape:\", input_tensor.shape)\n",
    "\n",
    "# Run the model\n",
    "output = model(input_tensor)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "In summary, PyTorch error messages are helpful, though can often be lengthy. Read them thoroughly, focusing on the parts directly related to your code. These messages typically provide helpful hints for resolving the issues. The issues sometimes stem from not defining the correct size of layers. Printing out the size of the data and the model might help find where in the model the incorrect layer sizes are defined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "This file &#169; 2024 by [WorldQuant University](https://www.wqu.edu/) is licensed under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
